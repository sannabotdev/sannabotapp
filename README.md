# ğŸ¤ Sanna â€“ Voice-First AI Assistant for Android

**What OpenClaw does for your desktop, Sanna does for your phone.**

An open-source AI assistant that runs on Android and actually *controls* your phone â€“ not just talks about it. Powered by an LLM agent loop (OpenAI or Claude) that reasons, chains actions, and executes tools until the job is done.

> "Hey Sanna, read my last 3 emails, summarize them, and text the summary to Sarah" â€” just works.

## âœ¨ Highlights

- **ğŸ—£ï¸ Voice-first** â€“ Wake word ("Hey Sanna") â†’ Speech-to-Text â†’ LLM agent â†’ Text-to-Speech, fully hands-free
- **ğŸ“ Skills are Markdown** â€“ Drop a `SKILL.md` in a folder, the agent learns a new capability. No code changes.
- **ğŸ”„ Agentic tool loop** â€“ LLM â†’ tool call â†’ result â†’ back to LLM, until final answer. Multi-step reasoning out of the box.
- **â° Sub-agent scheduler** â€“ Schedule natural-language tasks ("Every Monday at 9am, brief me on today's calendar via SMS"). A real LLM executes them â€“ not a dumb cron job.
- **ğŸš— Driving mode** â€“ Short spoken responses, auto-reads incoming notifications, optimized for hands-free use.
- **ğŸ”’ No backend needed** â€“ OAuth flows use PKCE. All data stays on your device.

## ğŸ“¦ 12 Built-in Skills

| Skill | What it does |
|-------|-------------|
| ğŸ“§ Gmail | Read, search, send, and reply to emails |
| ğŸ“… Calendar | Query and create Google Calendar events |
| âœ… Google Tasks | Manage task lists and items |
| ğŸ’¬ Slack | Read/send messages, manage DMs, set status |
| ğŸµ Spotify | Playback control via Web API |
| ğŸ“± WhatsApp | Send messages via Android Intents |
| ğŸ’¬ SMS | Send SMS directly in the background |
| ğŸ“ Phone | Make calls |
| ğŸ‘¤ Contacts | Search and query contacts |
| ğŸ—ºï¸ Google Maps | Start navigation |
| ğŸ”” Notifications | Intercept & summarize notifications from any app |
| â° Scheduler | Autonomous scheduled tasks with sub-agents |

## ğŸ—ï¸ Architecture

```
Wake Word (Picovoice) â†’ STT â†’ LLM Agent Loop â†’ Tool Execution â†’ TTS
                                    â†•
                           SKILL.md files (auto-discovered)
                                    â†•
                         Tools: intent, http, tts, device,
                         sms, query, scheduler, notifications
```

- **React Native** + native **Kotlin** modules for Android-specific features
- **LLM providers**: OpenAI (`gpt-4o`) or Anthropic Claude â€“ swap with one config line
- **Skill auto-discovery**: Metro's `require.context()` scans `assets/skills/*/SKILL.md` at build time
- **OAuth2 PKCE**: Google, Spotify, Slack â€“ no server, no client secret

## ğŸš€ Quick Start

1. Clone the repo
2. `cp local.config.example.ts local.config.ts` and add your API keys
3. `npm install && npm run android`

See [DEV_SETUP.md](DEV_SETUP.md) for detailed credential setup (API keys, OAuth, etc.).

## ğŸ“² Building an APK

**Debug APK** (for testing):

```bash
cd android
./gradlew assembleDebug
```

The APK will be at `android/app/build/outputs/apk/debug/app-debug.apk`.

**Release APK** (optimized, minified):

```bash
cd android
./gradlew assembleRelease
```

The APK will be at `android/app/build/outputs/release/app-release.apk`.

> **Note:** The release build currently uses the debug keystore. For production distribution, [generate your own keystore](https://reactnative.dev/docs/signed-apk-android) and update `android/app/build.gradle`.

You can also build and run directly on a connected device:

```bash
# Debug
npm run android

# Release
npm run android:release
```

## ğŸ¤ Adding a Skill

Create `assets/skills/your-skill/SKILL.md`:

```markdown
---
name: your-skill
description: What this skill does
---
# Your Skill

## Tool: http

### Do something

```json
{
  "method": "GET",
  "url": "https://api.example.com/endpoint",
  "auth_provider": "google"
}
```

That's it. No code changes. The agent picks it up automatically.

## ğŸ“„ License

MIT
